{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e61a6af-00f8-4ad0-ac8e-c07a394ce3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from resnet_features import resnet18_features, resnet34_features, resnet50_features, resnet101_features, resnet152_features\n",
    "from densenet_features import densenet121_features, densenet161_features, densenet169_features, densenet201_features\n",
    "from vgg_features import vgg11_features, vgg11_bn_features, vgg13_features, vgg13_bn_features, vgg16_features, vgg16_bn_features,\\\n",
    "                         vgg19_features, vgg19_bn_features\n",
    "\n",
    "from receptive_field import compute_proto_layer_rf_info_v2\n",
    "\n",
    "from settings import img_size\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data\n",
    "# import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "\n",
    "import pickle as pkl\n",
    "import skimage as sk\n",
    "import skimage.io as skio\n",
    "from preference_model import construct_PrefNet, paired_cross_entropy_loss, PrefNet\n",
    "\n",
    "# book keeping namings and code\n",
    "from settings import base_architecture, img_size, prototype_shape, num_classes, \\\n",
    "                     prototype_activation_function, add_on_layers_type, experiment_run\n",
    "\n",
    "from preprocess import mean, std, preprocess_input_function\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72e15376-1146-4353-b0d2-4d35fa3e00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_architecture_to_features = {'resnet18': resnet18_features,\n",
    "                                 'resnet34': resnet34_features,\n",
    "                                 'resnet50': resnet50_features,\n",
    "                                 'resnet101': resnet101_features,\n",
    "                                 'resnet152': resnet152_features,\n",
    "                                 'densenet121': densenet121_features,\n",
    "                                 'densenet161': densenet161_features,\n",
    "                                 'densenet169': densenet169_features,\n",
    "                                 'densenet201': densenet201_features,\n",
    "                                 'vgg11': vgg11_features,\n",
    "                                 'vgg11_bn': vgg11_bn_features,\n",
    "                                 'vgg13': vgg13_features,\n",
    "                                 'vgg13_bn': vgg13_bn_features,\n",
    "                                 'vgg16': vgg16_features,\n",
    "                                 'vgg16_bn': vgg16_bn_features,\n",
    "                                 'vgg19': vgg19_features,\n",
    "                                 'vgg19_bn': vgg19_bn_features}\n",
    "\n",
    "\n",
    "class PrefNet(nn.Module):\n",
    "\n",
    "    def __init__(self, features, img_size, prototype_shape,\n",
    "                 proto_layer_rf_info, num_classes, init_weights=True,\n",
    "                 prototype_activation_function='log',\n",
    "                 add_on_layers_type='bottleneck', \n",
    "                k = 3):\n",
    "\n",
    "        super(PrefNet, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.prototype_shape = prototype_shape\n",
    "        self.num_prototypes = prototype_shape[0]\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = 1e-4\n",
    "        self.k = k\n",
    "        \n",
    "        # this has to be named features to allow the precise loading\n",
    "        self.features = features\n",
    "\n",
    "        features_name = str(self.features).upper()\n",
    "        if features_name.startswith('VGG') or features_name.startswith('RES'):\n",
    "            first_add_on_layer_in_channels = \\\n",
    "                [i for i in features.modules() if isinstance(i, nn.Conv2d)][-1].out_channels\n",
    "        elif features_name.startswith('DENSE'):\n",
    "            first_add_on_layer_in_channels = \\\n",
    "                [i for i in features.modules() if isinstance(i, nn.BatchNorm2d)][-1].num_features\n",
    "        else:\n",
    "            raise Exception('other base base_architecture NOT implemented')\n",
    "\n",
    "        if add_on_layers_type == 'bottleneck':\n",
    "            add_on_layers = []\n",
    "            current_in_channels = first_add_on_layer_in_channels\n",
    "            while (current_in_channels > self.prototype_shape[1]) or (len(add_on_layers) == 0):\n",
    "                current_out_channels = max(self.prototype_shape[1], (current_in_channels // 2))\n",
    "                add_on_layers.append(nn.Conv2d(in_channels=current_in_channels,\n",
    "                                               out_channels=current_out_channels,\n",
    "                                               kernel_size=1))\n",
    "                add_on_layers.append(nn.ReLU())\n",
    "                add_on_layers.append(nn.Conv2d(in_channels=current_out_channels,\n",
    "                                               out_channels=current_out_channels,\n",
    "                                               kernel_size=1))\n",
    "                if current_out_channels > self.prototype_shape[1]:\n",
    "                    add_on_layers.append(nn.ReLU())\n",
    "                else:\n",
    "                    assert(current_out_channels == self.prototype_shape[1])\n",
    "                    add_on_layers.append(nn.Sigmoid())\n",
    "                current_in_channels = current_in_channels // 2\n",
    "            self.add_on_layers = nn.Sequential(*add_on_layers)\n",
    "        else:\n",
    "            self.add_on_layers = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=first_add_on_layer_in_channels, out_channels=self.prototype_shape[1], kernel_size=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=self.prototype_shape[1], out_channels=self.prototype_shape[1], kernel_size=1),\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "        \n",
    "#         self.prototype_vectors = nn.Parameter(torch.rand(self.prototype_shape),\n",
    "#                                               requires_grad=True)\n",
    "\n",
    "#         # do not make this just a tensor,\n",
    "#         # since it will not be moved automatically to gpu\n",
    "#         self.ones = nn.Parameter(torch.ones(self.prototype_shape),\n",
    "#                                  requires_grad=False)\n",
    "\n",
    "#         self.last_layer = nn.Linear(self.num_prototypes, self.num_classes,\n",
    "#                                     bias=False) # do not use bias\n",
    "\n",
    "\n",
    "        self.img_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=128, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        self.pattern_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=128, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        self.fc1 = nn.Linear(6400, 512)\n",
    "        self.fc2 = nn.Linear(512, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "            \n",
    "            \n",
    "    def conv_features(self, x):\n",
    "        '''\n",
    "        the feature input to prototype layer\n",
    "        '''\n",
    "        # Insert k and then img size\n",
    "        x = self.features(x)\n",
    "        x = self.add_on_layers(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, p):\n",
    "        # (N, 512, 7, 7)\n",
    "        x = self.conv_features(x)\n",
    "        x = self.img_conv(x)\n",
    "        #print(\"img_conv out shape: \", x.shape)\n",
    "        \n",
    "        p = self.conv_features(p)\n",
    "        p = self.pattern_conv(p)\n",
    "        #print(\"pattern_conv out shape: \", p.shape)\n",
    "        \n",
    "        out = torch.cat((x, p), dim=1)\n",
    "        #print(\"cat out shape: \", out.shape)\n",
    "        out = torch.flatten(out, 1) # flatten all dimensions except batch\n",
    "        #print(\"flatten out shape: \", out.shape)\n",
    "        \n",
    "       \n",
    "        out = torch.sigmoid(self.fc1(out))\n",
    "        out = torch.sigmoid(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.add_on_layers.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # every init technique has an underscore _ in the name\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "def construct_PrefNet(base_architecture, pretrained=True, img_size=224,\n",
    "                    prototype_shape=(2000, 512, 1, 1), num_classes=200,\n",
    "                    prototype_activation_function='log',\n",
    "                    add_on_layers_type='bottleneck',\n",
    "                    k = 3):\n",
    "    features = base_architecture_to_features[base_architecture](pretrained=pretrained)\n",
    "    layer_filter_sizes, layer_strides, layer_paddings = features.conv_info()\n",
    "    proto_layer_rf_info = compute_proto_layer_rf_info_v2(img_size=img_size,\n",
    "                                                         layer_filter_sizes=layer_filter_sizes,\n",
    "                                                         layer_strides=layer_strides,\n",
    "                                                         layer_paddings=layer_paddings,\n",
    "                                                         prototype_kernel_size=prototype_shape[2])\n",
    "    return PrefNet(features=features,\n",
    "                 img_size=img_size,\n",
    "                 prototype_shape=prototype_shape,\n",
    "                 proto_layer_rf_info=proto_layer_rf_info,\n",
    "                 num_classes=num_classes,\n",
    "                 init_weights=True,\n",
    "                 prototype_activation_function=prototype_activation_function,\n",
    "                 add_on_layers_type=add_on_layers_type,\n",
    "                 k = k)\n",
    "\n",
    "\n",
    "def paired_cross_entropy_loss(out1, out2, target):\n",
    "    if target == -1:\n",
    "        p1 = torch.exp(out1)/(torch.exp(out1) + torch.exp(out2))\n",
    "        loss = - torch.log(p1)\n",
    "    elif target == 1:\n",
    "        p2 = torch.exp(out2)/(torch.exp(out1) + torch.exp(out2))\n",
    "        loss = - torch.log(p2)\n",
    "        \n",
    "    else:\n",
    "        p1 = torch.exp(out1)/(torch.exp(out1) + torch.exp(out2))\n",
    "        p2 = torch.exp(out2)/(torch.exp(out1) + torch.exp(out2))\n",
    "        \n",
    "        loss = - (0.5*torch.log(p1) + 0.5*torch.log(p2))\n",
    "        \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39926c21-9702-4a73-82f3-ddfbfcdf7098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec93869e-6770-4067-926d-99e8b348d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=mean,\n",
    "                                 std=std)\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize(size=(img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11bcc1c8-6320-47bf-8b97-8301c097d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "csv_name = \"./human_comparisons/rating_s=5_k=1_500.csv\"\n",
    "if os.path.exists(csv_name):\n",
    "    comp_df = pd.read_csv(csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad6d69b5-9fd4-41a0-b87b-67e89bcffa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40449\n",
      "5021\n"
     ]
    }
   ],
   "source": [
    "split = 0.7\n",
    "df_len = len(comp_df)\n",
    "train_set = []\n",
    "test_set = []\n",
    "split_idx = int(df_len*split)\n",
    "for i in range(split_idx):\n",
    "    for j in range(i+1, split_idx):\n",
    "        if comp_df.iloc[i]['rating'] > comp_df.iloc[j]['rating']:\n",
    "            train_set.append([i, j, -1])\n",
    "        elif comp_df.iloc[i]['rating'] < comp_df.iloc[j]['rating']:\n",
    "            train_set.append([i, j, 1])\n",
    "            \n",
    "for i in range(split_idx, df_len):\n",
    "    for j in range(i+1, df_len):\n",
    "        if comp_df.iloc[i]['rating'] > comp_df.iloc[j]['rating']:\n",
    "            test_set.append([i, j, -1])\n",
    "        elif comp_df.iloc[i]['rating'] < comp_df.iloc[j]['rating']:\n",
    "            test_set.append([i, j, 1])\n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4352e7f6-affc-443c-83f1-966f474fb79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nanother way of splitting data\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "another way of splitting data\n",
    "'''\n",
    "#split = 0.7\n",
    "#train_set = training_set[:int(len(training_set) * split)]\n",
    "#test_set = training_set[int(len(training_set) * split):]\n",
    "#print(len(train_set))\n",
    "#print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c119e25-3c17-41fb-b90c-d830702acc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "patterns = []\n",
    "for i in range(df_len):\n",
    "    img = './human_comparisons/feedback_images/k=1/original_imgs/' + comp_df.iloc[i]['imgid'] + '.png'\n",
    "    img = plt.imread(img)[:, :, :3]\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    images.append(torch.from_numpy(np.array([img])))\n",
    "    pattern = './human_comparisons/feedback_images/k=1/patterns/' + comp_df.iloc[i]['imgid'] + '.npy'\n",
    "    pattern = np.load(pattern)\n",
    "    pattern = np.array([pattern, pattern, pattern])\n",
    "    patterns.append(torch.from_numpy(np.array([pattern])))\n",
    "print(len(images))\n",
    "print(images[100].shape)\n",
    "print(patterns[100].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b0696fc8-0923-49be-bf44-3e0660b85681",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefnet = construct_PrefNet(\"resnet18\")\n",
    "prefnet.to(device)\n",
    "prefnet.train()\n",
    "pref_optimizer = optim.Adam([{'params': prefnet.img_conv.parameters(), 'lr': 1e-4}, {'params': prefnet.pattern_conv.parameters(), 'lr': 1e-4}, {'params': prefnet.fc1.parameters(), 'lr': 1e-4},\n",
    "                            {'params': prefnet.fc2.parameters(), 'lr': 1e-4}, {'params': prefnet.fc3.parameters(), 'lr': 1e-4}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a540a57-6b9f-418c-bf90-6a4da17d3c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3610]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefnet(images[10].cuda(), patterns[10].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd22e4b8-0bb0-4563-a51b-a5cbacd06d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45935b65-b1ce-4334-b804-877048fcb3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref_optimizer = optim.Adam([{'params': prefnet.img_conv.parameters(), 'lr': 1e-5}, {'params': prefnet.pattern_conv.parameters(), 'lr': 1e-5}, {'params': prefnet.fc1.parameters(), 'lr': 1e-5},\n",
    "                            {'params': prefnet.fc2.parameters(), 'lr': 1e-5}, {'params': prefnet.fc3.parameters(), 'lr': 1e-5}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ebf1dc7-bd65-40ef-9107-ebc954e5aa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.0007888209\n",
      "0 99 0\n",
      "0 100 1.0788499e-05\n",
      "0 199 0\n",
      "0 200 0.0002191903\n",
      "0 299 0\n",
      "0 300 0.00019516466\n",
      "0 399 0\n",
      "0 400 0.00025484234\n",
      "0 499 0\n",
      "0 500 5.9604645e-08\n",
      "0 599 0\n",
      "0 600 7.212188e-06\n",
      "0 699 0\n",
      "0 700 1.0728842e-06\n",
      "0 799 0\n",
      "0 800 0.00023928167\n",
      "0 899 0\n",
      "0 900 5.9604645e-08\n",
      "0 999 0\n",
      "0 1000 0.0066432594\n",
      "0 1099 0\n",
      "0 1100 4.4466055e-05\n",
      "0 1199 0\n",
      "0 1200 0.0\n",
      "0 1299 0\n",
      "0 1300 7.15256e-07\n",
      "0 1399 0\n",
      "0 1400 6.556513e-07\n",
      "0 1499 0\n",
      "0 1500 0.00085688574\n",
      "0 1599 0\n",
      "0 1600 0.0002274772\n",
      "0 1699 0\n",
      "0 1700 0.001514747\n",
      "0 1799 0\n",
      "0 1800 0.00018246647\n",
      "0 1899 0\n",
      "0 1900 0.00062049803\n",
      "0 1999 0\n",
      "0 2000 0.00056097744\n",
      "0 2099 0\n",
      "0 2100 2.384186e-07\n",
      "0 2199 0\n",
      "0 2200 5.9604645e-08\n",
      "0 2299 0\n",
      "0 2300 0.00035977876\n",
      "0 2399 0\n",
      "0 2400 0.0\n",
      "0 2499 0\n",
      "0 2500 0.0\n",
      "0 2599 0\n",
      "0 2600 2.9802328e-07\n",
      "0 2699 0\n",
      "0 2700 0.00019713199\n",
      "0 2799 0\n",
      "0 2800 0.0029258574\n",
      "0 2899 0\n",
      "0 2900 0.00014872465\n",
      "0 2999 0\n",
      "0 3000 3.5762793e-07\n",
      "0 3099 0\n",
      "0 3100 4.875779e-05\n",
      "0 3199 0\n",
      "0 3200 0.00036109053\n",
      "0 3299 0\n",
      "0 3300 0.0\n",
      "0 3399 0\n",
      "0 3400 0.0\n",
      "0 3499 0\n",
      "0 3500 0.0\n",
      "0 3599 0\n",
      "0 3600 0.046305876\n",
      "0 3699 0\n",
      "0 3700 0.0003212014\n",
      "0 3799 0\n",
      "0 3800 0.0\n",
      "0 3899 0\n",
      "0 3900 5.9604645e-08\n",
      "0 3999 0\n",
      "0 4000 4.4168017e-05\n",
      "0 4099 0\n",
      "0 4100 0.00034755547\n",
      "0 4199 0\n",
      "0 4200 0.002932971\n",
      "0 4299 0\n",
      "0 4300 0.00016380698\n",
      "0 4399 0\n",
      "0 4400 0.0\n",
      "0 4499 0\n",
      "0 4500 0.00012219699\n",
      "0 4599 0\n",
      "0 4600 1.192093e-07\n",
      "0 4699 0\n",
      "0 4700 0.0\n",
      "0 4799 0\n",
      "0 4800 0.00044612106\n",
      "0 4899 0\n",
      "0 4900 9.5014315e-05\n",
      "0 4999 0\n",
      "0 5000 7.867844e-06\n",
      "0 5099 0\n",
      "0 5100 5.9604645e-08\n",
      "0 5199 0\n",
      "0 5200 0.0049194503\n",
      "0 5299 0\n",
      "0 5300 7.212188e-06\n",
      "0 5399 0\n",
      "0 5400 6.741512e-05\n",
      "0 5499 0\n",
      "0 5500 0.00044439174\n",
      "0 5599 0\n",
      "0 5600 0.00094160053\n",
      "0 5699 0\n",
      "0 5700 0.00017268957\n",
      "0 5799 0\n",
      "0 5800 0.0\n",
      "0 5899 0\n",
      "0 5900 0.0\n",
      "0 5999 0\n",
      "0 6000 1.192093e-07\n",
      "0 6099 0\n",
      "0 6100 0.007847863\n",
      "0 6199 0\n",
      "0 6200 0.0\n",
      "0 6299 0\n",
      "0 6300 0.0\n",
      "0 6399 0\n",
      "0 6400 5.9604645e-08\n",
      "0 6499 0\n",
      "0 6500 5.9604645e-08\n",
      "0 6599 0\n",
      "0 6600 0.0\n",
      "0 6699 0\n",
      "0 6700 0.00011867989\n",
      "0 6799 0\n",
      "0 6800 0.0001291716\n",
      "0 6899 0\n",
      "0 6900 6.5565323e-06\n",
      "0 6999 0\n",
      "0 7000 2.9802328e-07\n",
      "0 7099 0\n",
      "0 7100 0.0\n",
      "0 7199 0\n",
      "0 7200 0.0017762453\n",
      "0 7299 0\n",
      "0 7300 0.0\n",
      "0 7399 0\n",
      "0 7400 0.00013638473\n",
      "0 7499 0\n",
      "0 7500 5.9604645e-08\n",
      "0 7599 0\n",
      "0 7600 0.00030546085\n",
      "0 7699 0\n",
      "0 7700 0.0\n",
      "0 7799 0\n",
      "0 7800 0.0\n",
      "0 7899 0\n",
      "0 7900 0.00016666847\n",
      "0 7999 0\n",
      "0 8000 2.9802328e-07\n",
      "0 8099 0\n",
      "0 8100 0.0\n",
      "0 8199 0\n",
      "0 8200 0.0\n",
      "0 8299 0\n",
      "0 8300 5.9604645e-08\n",
      "0 8399 0\n",
      "0 8400 1.192093e-07\n",
      "0 8499 0\n",
      "0 8500 1.6033779e-05\n",
      "0 8599 0\n",
      "0 8600 0.0\n",
      "0 8699 0\n",
      "0 8700 1.192093e-07\n",
      "0 8799 0\n",
      "0 8800 0.00022735796\n",
      "0 8899 0\n",
      "0 8900 0.0\n",
      "0 8999 0\n",
      "0 9000 0.0\n",
      "0 9099 0\n",
      "0 9100 9.024551e-05\n",
      "0 9199 0\n",
      "0 9200 1.549722e-06\n",
      "0 9299 0\n",
      "0 9300 0.0004545291\n",
      "0 9399 0\n",
      "0 9400 0.0\n",
      "0 9499 0\n",
      "0 9500 1.192093e-07\n",
      "0 9599 0\n",
      "0 9600 1.7881395e-07\n",
      "0 9699 0\n",
      "0 9700 0.0006330228\n",
      "0 9799 0\n",
      "0 9800 0.00014258448\n",
      "0 9899 0\n",
      "0 9900 1.192093e-07\n",
      "0 9999 0\n",
      "0 10000 5.9604645e-08\n",
      "0 10099 0\n",
      "0 10100 0.0\n",
      "0 10199 0\n",
      "0 10200 0.00035107337\n",
      "0 10299 0\n",
      "0 10300 0.00026283143\n",
      "0 10399 0\n",
      "0 10400 0.00021531516\n",
      "0 10499 0\n",
      "0 10500 1.7881395e-07\n",
      "0 10599 0\n",
      "0 10600 0.00020804185\n",
      "0 10699 0\n",
      "0 10700 5.9604645e-08\n",
      "0 10799 0\n",
      "0 10800 1.192093e-07\n",
      "0 10899 0\n",
      "0 10900 0.00027308616\n",
      "0 10999 0\n",
      "0 11000 0.0\n",
      "0 11099 0\n",
      "0 11100 0.00023176972\n",
      "0 11199 0\n",
      "0 11200 1.192093e-07\n",
      "0 11299 0\n",
      "0 11300 0.0\n",
      "0 11399 0\n",
      "0 11400 5.36442e-07\n",
      "0 11499 0\n",
      "0 11500 0.00016398582\n",
      "0 11599 0\n",
      "0 11600 0.000263368\n",
      "0 11699 0\n",
      "0 11700 1.192093e-07\n",
      "0 11799 0\n",
      "0 11800 0.0018396003\n",
      "0 11899 0\n",
      "0 11900 0.0\n",
      "0 11999 0\n",
      "0 12000 0.0\n",
      "0 12099 0\n",
      "0 12100 0.0\n",
      "0 12199 0\n",
      "0 12200 0.0\n",
      "0 12299 0\n",
      "0 12300 0.0\n",
      "0 12399 0\n",
      "0 12400 5.36442e-07\n",
      "0 12499 0\n",
      "0 12500 1.192093e-07\n",
      "0 12599 0\n",
      "0 12600 0.0\n",
      "0 12699 0\n",
      "0 12700 0.0\n",
      "0 12799 0\n",
      "0 12800 0.0\n",
      "0 12899 0\n",
      "0 12900 0.0\n",
      "0 12999 0\n",
      "0 13000 0.00019397233\n",
      "0 13099 0\n",
      "0 13100 0.0\n",
      "0 13199 0\n",
      "0 13200 0.00022312507\n",
      "0 13299 0\n",
      "0 13300 9.5789255e-05\n",
      "0 13399 0\n",
      "0 13400 0.0\n",
      "0 13499 0\n",
      "0 13500 0.0\n",
      "0 13599 0\n",
      "0 13600 0.0\n",
      "0 13699 0\n",
      "0 13700 0.0\n",
      "0 13799 0\n",
      "0 13800 0.0008836119\n",
      "0 13899 0\n",
      "0 13900 0.0\n",
      "0 13999 0\n",
      "0 14000 0.0\n",
      "0 14099 0\n",
      "0 14100 1.192093e-07\n",
      "0 14199 0\n",
      "0 14200 2.384186e-07\n",
      "0 14299 0\n",
      "0 14300 0.00062127336\n",
      "0 14399 0\n",
      "0 14400 0.0003640122\n",
      "0 14499 0\n",
      "0 14500 0.00017620686\n",
      "0 14599 0\n",
      "0 14600 5.9604645e-08\n",
      "0 14699 0\n",
      "0 14700 0.00019659544\n",
      "0 14799 0\n",
      "0 14800 0.0\n",
      "0 14899 0\n",
      "0 14900 0.00013125804\n",
      "0 14999 0\n",
      "0 15000 5.0307586e-05\n",
      "0 15099 0\n",
      "0 15100 0.0\n",
      "0 15199 0\n",
      "0 15200 0.00011403019\n",
      "0 15299 0\n",
      "0 15300 5.9604645e-08\n",
      "0 15399 0\n",
      "0 15400 0.0\n",
      "0 15499 0\n",
      "0 15500 5.9604645e-08\n",
      "0 15599 0\n",
      "0 15600 2.4437934e-06\n",
      "0 15699 0\n",
      "0 15700 0.0\n",
      "0 15799 0\n",
      "0 15800 0.0\n",
      "0 15899 0\n",
      "0 15900 9.143771e-05\n",
      "0 15999 0\n",
      "0 16000 0.0\n",
      "0 16099 0\n",
      "0 16100 0.00014067686\n",
      "0 16199 0\n",
      "0 16200 0.0\n",
      "0 16299 0\n",
      "0 16300 0.00013602705\n",
      "0 16399 0\n",
      "0 16400 8.350959e-05\n",
      "0 16499 0\n",
      "0 16500 5.9604645e-08\n",
      "0 16599 0\n",
      "0 16600 9.304718e-05\n",
      "0 16699 0\n",
      "0 16700 9.036472e-05\n",
      "0 16799 0\n",
      "0 16800 7.182618e-05\n",
      "0 16899 0\n",
      "0 16900 0.0008734702\n",
      "0 16999 0\n",
      "0 17000 0.0\n",
      "0 17099 0\n",
      "0 17100 0.00014377674\n",
      "0 17199 0\n",
      "0 17200 0.0\n",
      "0 17299 0\n",
      "0 17300 9.48951e-05\n",
      "0 17399 0\n",
      "0 17400 7.242226e-05\n",
      "0 17499 0\n",
      "0 17500 8.7265005e-05\n",
      "0 17599 0\n",
      "0 17600 4.768373e-07\n",
      "0 17699 0\n",
      "0 17700 1.192093e-07\n",
      "0 17799 0\n",
      "0 17800 2.861027e-06\n",
      "0 17899 0\n",
      "0 17900 5.9604645e-08\n",
      "0 17999 0\n",
      "0 18000 1.192093e-07\n",
      "0 18099 0\n",
      "0 18100 5.9604645e-08\n",
      "0 18199 0\n",
      "0 18200 0.0\n",
      "0 18299 0\n",
      "0 18300 0.00012130281\n",
      "0 18399 0\n",
      "0 18400 1.192093e-07\n",
      "0 18499 0\n",
      "0 18500 0.0\n",
      "0 18599 0\n",
      "0 18600 5.9604645e-08\n",
      "0 18699 0\n",
      "0 18700 0.0\n",
      "0 18799 0\n",
      "0 18800 0.00015879938\n",
      "0 18899 0\n",
      "0 18900 0.0\n",
      "0 18999 0\n",
      "0 19000 0.0\n",
      "0 19099 0\n",
      "0 19100 0.00015224185\n",
      "0 19199 0\n",
      "0 19200 1.192093e-07\n",
      "0 19299 0\n",
      "0 19300 0.00013000618\n",
      "0 19399 0\n",
      "0 19400 0.0\n",
      "0 19499 0\n",
      "0 19500 3.5762793e-07\n",
      "0 19599 0\n",
      "0 19600 0.0\n",
      "0 19699 0\n",
      "0 19700 0.0\n",
      "0 19799 0\n",
      "0 19800 5.960466e-07\n",
      "0 19899 0\n",
      "0 19900 0.000112718735\n",
      "0 19999 0\n",
      "0 20000 3.9935194e-06\n",
      "0 20099 0\n",
      "0 20100 1.192093e-07\n",
      "0 20199 0\n",
      "0 20200 1.192093e-07\n",
      "0 20299 0\n",
      "0 20300 0.0009944614\n",
      "0 20399 0\n",
      "0 20400 8.3330764e-05\n",
      "0 20499 0\n",
      "0 20500 0.0\n",
      "0 20599 0\n",
      "0 20600 0.0025777037\n",
      "0 20699 0\n",
      "0 20700 0.00042799333\n",
      "0 20799 0\n",
      "0 20800 0.000114447466\n",
      "0 20899 0\n",
      "0 20900 0.000119931734\n",
      "0 20999 0\n",
      "0 21000 1.192093e-07\n",
      "0 21099 0\n",
      "0 21100 0.00037569905\n",
      "0 21199 0\n",
      "0 21200 0.00013966343\n",
      "0 21299 0\n",
      "0 21300 0.0\n",
      "0 21399 0\n",
      "0 21400 9.536748e-07\n",
      "0 21499 0\n",
      "0 21500 0.00061340065\n",
      "0 21599 0\n",
      "0 21600 0.0\n",
      "0 21699 0\n",
      "0 21700 0.00024768797\n",
      "0 21799 0\n",
      "0 21800 5.9604645e-08\n",
      "0 21899 0\n",
      "0 21900 0.00014169028\n",
      "0 21999 0\n",
      "0 22000 0.001355195\n",
      "0 22099 0\n",
      "0 22100 0.0\n",
      "0 22199 0\n",
      "0 22200 0.0\n",
      "0 22299 0\n",
      "0 22300 8.666891e-05\n",
      "0 22399 0\n",
      "0 22400 0.00015683212\n",
      "0 22499 0\n",
      "0 22500 0.0\n",
      "0 22599 0\n",
      "0 22600 0.0\n",
      "0 22699 0\n",
      "0 22700 5.5255034e-05\n",
      "0 22799 0\n",
      "0 22800 0.00013084075\n",
      "0 22899 0\n",
      "0 22900 0.0\n",
      "0 22999 0\n",
      "0 23000 3.5762793e-07\n",
      "0 23099 0\n",
      "0 23100 0.0\n",
      "0 23199 0\n",
      "0 23200 0.0\n",
      "0 23299 0\n",
      "0 23300 0.0\n",
      "0 23399 0\n",
      "0 23400 7.468741e-05\n",
      "0 23499 0\n",
      "0 23500 7.337601e-05\n",
      "0 23599 0\n",
      "0 23600 9.328562e-05\n",
      "0 23699 0\n",
      "0 23700 0.0\n",
      "0 23799 0\n",
      "0 23800 7.0693604e-05\n",
      "0 23899 0\n",
      "0 23900 6.914378e-05\n",
      "0 23999 0\n",
      "0 24000 2.384186e-07\n",
      "0 24099 0\n",
      "0 24100 0.0\n",
      "0 24199 0\n",
      "0 24200 7.695256e-05\n",
      "0 24299 0\n",
      "0 24300 0.0\n",
      "0 24399 0\n",
      "0 24400 0.0\n",
      "0 24499 0\n",
      "0 24500 0.0\n",
      "0 24599 0\n",
      "0 24600 8.142326e-05\n",
      "0 24699 0\n",
      "0 24700 7.736982e-05\n",
      "0 24799 0\n",
      "0 24800 0.0003352131\n",
      "0 24899 0\n",
      "0 24900 3.5762793e-07\n",
      "0 24999 0\n",
      "0 25000 7.105126e-05\n",
      "0 25099 0\n",
      "0 25100 0.00014878427\n",
      "0 25199 0\n",
      "0 25200 4.8877002e-05\n",
      "0 25299 0\n",
      "0 25300 0.0\n",
      "0 25399 0\n",
      "0 25400 8.440374e-05\n",
      "0 25499 0\n",
      "0 25500 0.0\n",
      "0 25599 0\n",
      "0 25600 0.0\n",
      "0 25699 0\n",
      "0 25700 5.9604645e-08\n",
      "0 25799 0\n",
      "0 25800 0.0\n",
      "0 25899 0\n",
      "0 25900 0.0\n",
      "0 25999 0\n",
      "0 26000 9.537198e-05\n",
      "0 26099 0\n",
      "0 26100 3.218656e-06\n",
      "0 26199 0\n",
      "0 26200 0.00038070773\n",
      "0 26299 0\n",
      "0 26300 0.0\n",
      "0 26399 0\n",
      "0 26400 0.004594733\n",
      "0 26499 0\n",
      "0 26500 0.0\n",
      "0 26599 0\n",
      "0 26600 0.00011856067\n",
      "0 26699 0\n",
      "0 26700 0.0\n",
      "0 26799 0\n",
      "0 26800 7.206461e-05\n",
      "0 26899 0\n",
      "0 26900 5.9604645e-08\n",
      "0 26999 0\n",
      "0 27000 8.201935e-05\n",
      "0 27099 0\n",
      "0 27100 6.461352e-05\n",
      "0 27199 0\n",
      "0 27200 0.0\n",
      "0 27299 0\n",
      "0 27300 0.00012291233\n",
      "0 27399 0\n",
      "0 27400 0.00022211157\n",
      "0 27499 0\n",
      "0 27500 6.93226e-05\n",
      "0 27599 0\n",
      "0 27600 0.0\n",
      "0 27699 0\n",
      "0 27700 7.72506e-05\n",
      "0 27799 0\n",
      "0 27800 0.00027135716\n",
      "0 27899 0\n",
      "0 27900 0.0\n",
      "0 27999 0\n",
      "0 28000 0.0\n",
      "0 28099 0\n",
      "0 28100 0.0\n",
      "0 28199 0\n",
      "0 28200 0.0\n",
      "0 28299 0\n",
      "0 28300 0.00010455201\n",
      "0 28399 0\n",
      "0 28400 0.0\n",
      "0 28499 0\n",
      "0 28500 9.4775874e-05\n",
      "0 28599 0\n",
      "0 28600 0.0005666431\n",
      "0 28699 0\n",
      "0 28700 5.8891124e-05\n",
      "0 28799 0\n",
      "0 28800 9.161654e-05\n",
      "0 28899 0\n",
      "0 28900 0.0\n",
      "0 28999 0\n",
      "0 29000 0.0\n",
      "0 29099 0\n",
      "0 29100 0.0\n",
      "0 29199 0\n",
      "0 29200 0.0\n",
      "0 29299 0\n",
      "0 29300 0.000106698004\n",
      "0 29399 0\n",
      "0 29400 0.0008241353\n",
      "0 29499 0\n",
      "0 29500 9.572964e-05\n",
      "0 29599 0\n",
      "0 29600 0.0\n",
      "0 29699 0\n",
      "0 29700 6.3898224e-05\n",
      "0 29799 0\n",
      "0 29800 0.0015765929\n",
      "0 29899 0\n",
      "0 29900 0.00012642944\n",
      "0 29999 0\n",
      "0 30000 0.0\n",
      "0 30099 0\n",
      "0 30100 0.0\n",
      "0 30199 0\n",
      "0 30200 9.274913e-05\n",
      "0 30299 0\n",
      "0 30300 0.0002495958\n",
      "0 30399 0\n",
      "0 30400 2.9802328e-07\n",
      "0 30499 0\n",
      "0 30500 5.000955e-05\n",
      "0 30599 0\n",
      "0 30600 5.310915e-05\n",
      "0 30699 0\n",
      "0 30700 0.0\n",
      "0 30799 0\n",
      "0 30800 0.0\n",
      "0 30899 0\n",
      "0 30900 0.00011307641\n",
      "0 30999 0\n",
      "0 31000 0.0\n",
      "0 31099 0\n",
      "0 31100 0.0\n",
      "0 31199 0\n",
      "0 31200 0.00017370303\n",
      "0 31299 0\n",
      "0 31300 0.0\n",
      "0 31399 0\n",
      "0 31400 0.0\n",
      "0 31499 0\n",
      "0 31500 4.3810374e-05\n",
      "0 31599 0\n",
      "0 31600 0.0005836401\n",
      "0 31699 0\n",
      "0 31700 0.0\n",
      "0 31799 0\n",
      "0 31800 0.00124347\n",
      "0 31899 0\n",
      "0 31900 2.384186e-07\n",
      "0 31999 0\n",
      "0 32000 0.0\n",
      "0 32099 0\n",
      "0 32100 0.00013417906\n",
      "0 32199 0\n",
      "0 32200 0.0\n",
      "0 32299 0\n",
      "0 32300 7.498545e-05\n",
      "0 32399 0\n",
      "0 32400 5.555307e-05\n",
      "0 32499 0\n",
      "0 32500 3.838613e-05\n",
      "0 32599 0\n",
      "0 32600 4.768373e-07\n",
      "0 32699 0\n",
      "0 32700 0.00023755273\n",
      "0 32799 0\n",
      "0 32800 0.0\n",
      "0 32899 0\n",
      "0 32900 0.0\n",
      "0 32999 0\n",
      "0 33000 8.118482e-05\n",
      "0 33099 0\n",
      "0 33100 0.0005104056\n",
      "0 33199 0\n",
      "0 33200 5.012876e-05\n",
      "0 33299 0\n",
      "0 33300 0.0\n",
      "0 33399 0\n",
      "0 33400 0.0\n",
      "0 33499 0\n",
      "0 33500 6.5805696e-05\n",
      "0 33599 0\n",
      "0 33600 0.0\n",
      "0 33699 0\n",
      "0 33700 0.0\n",
      "0 33799 0\n",
      "0 33800 7.1706956e-05\n",
      "0 33899 0\n",
      "0 33900 0.0\n",
      "0 33999 0\n",
      "0 34000 3.6001853e-05\n",
      "0 34099 0\n",
      "0 34100 7.7486067e-07\n",
      "0 34199 0\n",
      "0 34200 0.0\n",
      "0 34299 0\n",
      "0 34300 0.000103896295\n",
      "0 34399 0\n",
      "0 34400 5.7758567e-05\n",
      "0 34499 0\n",
      "0 34500 6.5030785e-05\n",
      "0 34599 0\n",
      "0 34600 4.196255e-05\n",
      "0 34699 0\n",
      "0 34700 5.9546812e-05\n",
      "0 34799 0\n",
      "0 34800 0.00015212262\n",
      "0 34899 0\n",
      "0 34900 0.0\n",
      "0 34999 0\n",
      "0 35000 0.0\n",
      "0 35099 0\n",
      "0 35100 4.875779e-05\n",
      "0 35199 0\n",
      "0 35200 0.0\n",
      "0 35299 0\n",
      "0 35300 0.0\n",
      "0 35399 0\n",
      "0 35400 2.1457695e-06\n",
      "0 35499 0\n",
      "0 35500 0.00011748766\n",
      "0 35599 0\n",
      "0 35600 5.9604645e-08\n",
      "0 35699 0\n",
      "0 35700 6.16331e-05\n",
      "0 35799 0\n",
      "0 35800 6.175232e-05\n",
      "0 35899 0\n",
      "0 35900 0.0\n",
      "0 35999 0\n",
      "0 36000 0.0\n",
      "0 36099 0\n",
      "0 36100 0.0\n",
      "0 36199 0\n",
      "0 36200 0.00022580789\n",
      "0 36299 0\n",
      "0 36300 6.395783e-05\n",
      "0 36399 0\n",
      "0 36400 0.0\n",
      "0 36499 0\n",
      "0 36500 0.0\n",
      "0 36599 0\n",
      "0 36600 0.0\n",
      "0 36699 0\n",
      "0 36700 0.00010002159\n",
      "0 36799 0\n",
      "0 36800 0.0\n",
      "0 36899 0\n",
      "0 36900 0.00068258686\n",
      "0 36999 0\n",
      "0 37000 3.6299887e-05\n",
      "0 37099 0\n",
      "0 37100 4.7148387e-05\n",
      "0 37199 0\n",
      "0 37200 0.00022866957\n",
      "0 37299 0\n",
      "0 37300 0.0\n",
      "0 37399 0\n",
      "0 37400 0.0001720338\n",
      "0 37499 0\n",
      "0 37500 2.384186e-07\n",
      "0 37599 0\n",
      "0 37600 0.00014389596\n",
      "0 37699 0\n",
      "0 37700 0.0002171633\n",
      "0 37799 0\n",
      "0 37800 0.00015051305\n",
      "0 37899 0\n",
      "0 37900 0.0\n",
      "0 37999 0\n",
      "0 38000 0.0\n",
      "0 38099 0\n",
      "0 38100 0.0\n",
      "0 38199 0\n",
      "0 38200 0.0\n",
      "0 38299 0\n",
      "0 38300 5.096327e-05\n",
      "0 38399 0\n",
      "0 38400 0.0\n",
      "0 38499 0\n",
      "0 38500 5.7937392e-05\n",
      "0 38599 0\n",
      "0 38600 6.72363e-05\n",
      "0 38699 0\n",
      "0 38700 0.0\n",
      "0 38799 0\n",
      "0 38800 0.0001920646\n",
      "0 38899 0\n",
      "0 38900 0.0006434603\n",
      "0 38999 0\n",
      "0 39000 0.0\n",
      "0 39099 0\n",
      "0 39100 0.0\n",
      "0 39199 0\n",
      "0 39200 0.0\n",
      "0 39299 0\n",
      "0 39300 6.759395e-05\n",
      "0 39399 0\n",
      "0 39400 0.0\n",
      "0 39499 0\n",
      "0 39500 0.0\n",
      "0 39599 0\n",
      "0 39600 0.0\n",
      "0 39699 0\n",
      "0 39700 0.00017960492\n",
      "0 39799 0\n",
      "0 39800 0.0\n",
      "0 39899 0\n",
      "0 39900 0.0\n",
      "0 39999 0\n",
      "0 40000 0.0001207663\n",
      "0 40099 0\n",
      "0 40100 0.0\n",
      "0 40199 0\n",
      "0 40200 3.8564947e-05\n",
      "0 40299 0\n",
      "0 40300 0.0\n",
      "0 40399 0\n",
      "0 40400 6.032172e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    shuffled_idx = np.random.permutation(len(train_set))\n",
    "    for i in range(len(train_set)):\n",
    "        if i % 100 == 0:\n",
    "            last_100_losses = []\n",
    "            last_100_error_count = 0\n",
    "        idx = shuffled_idx[i]\n",
    "        left_idx, right_idx, target = train_set[idx]\n",
    "        left_img, right_img = images[left_idx], images[right_idx]\n",
    "        left_pattern, right_pattern = patterns[left_idx], patterns[right_idx]\n",
    "        target = torch.tensor(target).cuda().float()\n",
    "        \n",
    "        out1 = prefnet(left_img.cuda().float(), left_pattern.cuda().float())\n",
    "        out2 = prefnet(right_img.cuda().float(), right_pattern.cuda().float())\n",
    "\n",
    "        # in your training loop:\n",
    "        pref_optimizer.zero_grad()   # zero the gradient buffers\n",
    "        if out1 > out2 and target == 1:\n",
    "            last_100_error_count += 1\n",
    "            \n",
    "        elif out1 < out2 and target == -1:\n",
    "            last_100_error_count += 1\n",
    "        loss = paired_cross_entropy_loss(out1, out2, target)\n",
    "        loss.backward()\n",
    "        pref_optimizer.step()   \n",
    "        \n",
    "        last_100_losses.append(loss.data.cpu().numpy()[0])\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(epoch, i, np.sum(last_100_losses))\n",
    "        if i % 100 == 99:\n",
    "            print(epoch, i, last_100_error_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49c1ce3d-048d-4367-a947-76ab715c655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prefnet = torch.load('./human_comparisons/pref_model_500rating_split0.7_acc0.82.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "41806b60-cc3d-47e1-b42e-dfd512fe9027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5021/5021 [01:04<00:00, 77.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8111929894443338 948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Testing reward model\n",
    "'''\n",
    "acc = []\n",
    "#error_images = []\n",
    "error_count = 0\n",
    "for i in tqdm(range(len(test_set))):\n",
    "    left_idx, right_idx, target = test_set[i]\n",
    "    left_img, right_img = images[left_idx], images[right_idx]\n",
    "    left_pattern, right_pattern = patterns[left_idx], patterns[right_idx]\n",
    "    target = torch.tensor(target).cuda().float()\n",
    "\n",
    "    out1 = prefnet(left_img.cuda().float(), left_pattern.cuda().float())\n",
    "    out2 = prefnet(right_img.cuda().float(), right_pattern.cuda().float())\n",
    "    #print(out1)\n",
    "    #print(out2)\n",
    "    \n",
    "    \n",
    "    if out1 > out2:\n",
    "        y_pred = -1\n",
    "        \n",
    "    else:\n",
    "        y_pred = 1\n",
    "    \n",
    "    #print(y_pred)\n",
    "    #print(\"\")\n",
    "    if y_pred == target:\n",
    "        acc.append(1)\n",
    "    else:\n",
    "        #error_images.append((i, y_pred, target))\n",
    "        error_count += 1\n",
    "        acc.append(0)\n",
    "    #print(out1, out2, target)\n",
    "        \n",
    "print(np.mean(acc), error_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9d0aa508-1489-47c6-9f1c-85d979a0ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(prefnet, './human_comparisons/pref_model_500rating_split0.7_acc0.82.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edcc0bd-3c16-4279-8032-5f5c4a1b724d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
