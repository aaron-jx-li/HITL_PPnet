{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4fc4916-c7e1-4989-a8d6-7b052156a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import heapq\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "\n",
    "from receptive_field import compute_rf_prototype\n",
    "from helpers import makedir, find_high_activation_crop\n",
    "import shutil\n",
    "\n",
    "import torch.utils.data\n",
    "import pandas as pd\n",
    "# import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "from helpers import makedir\n",
    "import model\n",
    "import push\n",
    "import prune\n",
    "import train_and_test as tnt\n",
    "import save\n",
    "from log import create_logger\n",
    "from preprocess import mean, std, preprocess_input_function\n",
    "\n",
    "from bounding_box_metrics import bounding_box_overlap\n",
    "from find_nearest import find_k_nearest_patches_to_prototypes, imsave_with_bbox, ImagePatch, ImagePatchInfo\n",
    "\n",
    "from settings import train_dir, test_dir, train_push_dir, train_batch_size, test_batch_size, train_push_batch_size\n",
    "from settings import base_architecture, img_size, prototype_shape, num_classes, prototype_activation_function, add_on_layers_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a19d46-b3df-4c90-a7c0-81952c193e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppnet = torch.load(r'../saved_models/vgg19/004/100_7push0.7344.pth')\n",
    "ppnet = ppnet.cuda()\n",
    "ppnet_multi = torch.nn.DataParallel(ppnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2727883c-c8c1-4484-b832-6176d28295b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "        train_push_dir,\n",
    "        transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "train_push_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, shuffle=True,\n",
    "    num_workers=2, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accd01e8-15ac-4b2d-bddd-c0b2af642e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 5995\n",
       "    Root location: /accounts/projects/binyu/jiaxun1218/data/CUB_200_2011_cropped/train_cropped/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c783a5d1-be73-4f0b-ba2d-b7aa2e8f68f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef find_nearest_offline(dataloader, \\n                         prototype_network_parallel, \\n                         k=5,\\n                         preprocess_input_function=None,\\n                         root_dir_for_saving_images,\\n                         prototype_activation_function_in_numpy=None):\\n    \\n    prototype_network.parallel.eval()\\n    print('Starting to find nearest patches...')\\n    start = time.time()\\n    \\n    n_prototypes = prototype_network_parallel.module.num_prototypes\\n    \\n    prototype_shape = prototype_network_parallel.module.prototype_shape\\n    max_dist = prototype_shape[1] * prototype_shape[2] * prototype_shape[3]\\n\\n    protoL_rf_info = prototype_network_parallel.module.proto_layer_rf_info\\n    \\n    heaps = []\\n    \\n    for _ in range(n_prototypes):\\n        # a heap in python is just a maintained list\\n        heaps.append([])\\n    \\n    for idx, (search_batch_input, search_y) in enumerate(dataloader):\\n        print('batch {}'.format(idx))\\n        if preprocess_input_function is not None:\\n            # print('preprocessing input for pushing ...')\\n            # search_batch = copy.deepcopy(search_batch_input)\\n            search_batch = preprocess_input_function(search_batch_input)\\n\\n        else:\\n            search_batch = search_batch_input\\n\\n        with torch.no_grad():\\n            search_batch = search_batch.cuda()\\n            protoL_input_torch, proto_dist_torch =                 prototype_network_parallel.module.push_forward(search_batch)\\n\\n        #protoL_input_ = np.copy(protoL_input_torch.detach().cpu().numpy())\\n        proto_dist_ = np.copy(proto_dist_torch.detach().cpu().numpy())\\n        \\n        for img_idx, distance_map in enumerate(proto_dist_):\\n            for j in range(n_prototypes):\\n                # find the closest patches in this batch to prototype j\\n                closest_patch_distance_to_prototype_j = np.amin(distance_map[j])\\n\\n\\n                closest_patch_indices_in_distance_map_j =                     list(np.unravel_index(np.argmin(distance_map[j],axis=None),\\n                                          distance_map[j].shape))\\n                closest_patch_indices_in_distance_map_j = [0] + closest_patch_indices_in_distance_map_j\\n                closest_patch_indices_in_img =                     compute_rf_prototype(search_batch.size(2),\\n                                         closest_patch_indices_in_distance_map_j,\\n                                         protoL_rf_info)\\n                closest_patch =                     search_batch_input[img_idx, :,\\n                                       closest_patch_indices_in_img[1]:closest_patch_indices_in_img[2],\\n                                       closest_patch_indices_in_img[3]:closest_patch_indices_in_img[4]]\\n                closest_patch = closest_patch.numpy()\\n                closest_patch = np.transpose(closest_patch, (1, 2, 0))\\n\\n                original_img = search_batch_input[img_idx].numpy()\\n                original_img = np.transpose(original_img, (1, 2, 0))\\n\\n                if prototype_network_parallel.module.prototype_activation_function == 'log':\\n                    act_pattern = np.log((distance_map[j] + 1)/(distance_map[j] + prototype_network_parallel.module.epsilon))\\n                elif prototype_network_parallel.module.prototype_activation_function == 'linear':\\n                    act_pattern = max_dist - distance_map[j]\\n                else:\\n                    act_pattern = prototype_activation_function_in_numpy(distance_map[j])\\n                    \\n                upsampled_act_img = cv2.resize(act_pattern, dsize=(original_img_size, original_img_size),\\n                                             interpolation=cv2.INTER_CUBIC)\\n\\n                rescaled_act_img = upsampled_act_img - np.amin(upsampled_act_img)\\n                rescaled_act_img = rescaled_act_img / np.amax(rescaled_act_img)\\n                \\n                heatmap = cv2.applyColorMap(np.uint8(255*rescaled_act_img), cv2.COLORMAP_JET)\\n                heatmap = np.float32(heatmap) / 255\\n                heatmap = heatmap[...,::-1]\\n                overlayed_original_img = 0.5 * original_img + 0.3 * heatmap\\n                \\n                # construct the closest patch object\\n                \\n\\n                # add to the j-th heap \\n                if len(heaps[j]) < k:\\n                    heapq.heappush(heaps[j], closest_patch)\\n                else:\\n                    # heappushpop runs more efficiently than heappush\\n                    # followed by heappop\\n                    heapq.heappushpop(heaps[j], closest_patch)\\n                    \\n    for j in range(n_prototypes):\\n        heaps[j].sort()\\n        heaps[j] = heaps[j][::-1]\\n        dir_for_saving_images = os.path.join(root_dir_for_saving_images, str(j))\\n        makedir(dir_for_saving_images)\\n        for i, patch in enumerate(heaps[j]):\\n            \\n    \\n    return\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def find_nearest_offline(dataloader, \n",
    "                         prototype_network_parallel, \n",
    "                         k=5,\n",
    "                         preprocess_input_function=None,\n",
    "                         root_dir_for_saving_images,\n",
    "                         prototype_activation_function_in_numpy=None):\n",
    "    \n",
    "    prototype_network.parallel.eval()\n",
    "    print('Starting to find nearest patches...')\n",
    "    start = time.time()\n",
    "    \n",
    "    n_prototypes = prototype_network_parallel.module.num_prototypes\n",
    "    \n",
    "    prototype_shape = prototype_network_parallel.module.prototype_shape\n",
    "    max_dist = prototype_shape[1] * prototype_shape[2] * prototype_shape[3]\n",
    "\n",
    "    protoL_rf_info = prototype_network_parallel.module.proto_layer_rf_info\n",
    "    \n",
    "    heaps = []\n",
    "    \n",
    "    for _ in range(n_prototypes):\n",
    "        # a heap in python is just a maintained list\n",
    "        heaps.append([])\n",
    "    \n",
    "    for idx, (search_batch_input, search_y) in enumerate(dataloader):\n",
    "        print('batch {}'.format(idx))\n",
    "        if preprocess_input_function is not None:\n",
    "            # print('preprocessing input for pushing ...')\n",
    "            # search_batch = copy.deepcopy(search_batch_input)\n",
    "            search_batch = preprocess_input_function(search_batch_input)\n",
    "\n",
    "        else:\n",
    "            search_batch = search_batch_input\n",
    "\n",
    "        with torch.no_grad():\n",
    "            search_batch = search_batch.cuda()\n",
    "            protoL_input_torch, proto_dist_torch = \\\n",
    "                prototype_network_parallel.module.push_forward(search_batch)\n",
    "\n",
    "        #protoL_input_ = np.copy(protoL_input_torch.detach().cpu().numpy())\n",
    "        proto_dist_ = np.copy(proto_dist_torch.detach().cpu().numpy())\n",
    "        \n",
    "        for img_idx, distance_map in enumerate(proto_dist_):\n",
    "            for j in range(n_prototypes):\n",
    "                # find the closest patches in this batch to prototype j\n",
    "                closest_patch_distance_to_prototype_j = np.amin(distance_map[j])\n",
    "\n",
    "\n",
    "                closest_patch_indices_in_distance_map_j = \\\n",
    "                    list(np.unravel_index(np.argmin(distance_map[j],axis=None),\n",
    "                                          distance_map[j].shape))\n",
    "                closest_patch_indices_in_distance_map_j = [0] + closest_patch_indices_in_distance_map_j\n",
    "                closest_patch_indices_in_img = \\\n",
    "                    compute_rf_prototype(search_batch.size(2),\n",
    "                                         closest_patch_indices_in_distance_map_j,\n",
    "                                         protoL_rf_info)\n",
    "                closest_patch = \\\n",
    "                    search_batch_input[img_idx, :,\n",
    "                                       closest_patch_indices_in_img[1]:closest_patch_indices_in_img[2],\n",
    "                                       closest_patch_indices_in_img[3]:closest_patch_indices_in_img[4]]\n",
    "                closest_patch = closest_patch.numpy()\n",
    "                closest_patch = np.transpose(closest_patch, (1, 2, 0))\n",
    "\n",
    "                original_img = search_batch_input[img_idx].numpy()\n",
    "                original_img = np.transpose(original_img, (1, 2, 0))\n",
    "\n",
    "                if prototype_network_parallel.module.prototype_activation_function == 'log':\n",
    "                    act_pattern = np.log((distance_map[j] + 1)/(distance_map[j] + prototype_network_parallel.module.epsilon))\n",
    "                elif prototype_network_parallel.module.prototype_activation_function == 'linear':\n",
    "                    act_pattern = max_dist - distance_map[j]\n",
    "                else:\n",
    "                    act_pattern = prototype_activation_function_in_numpy(distance_map[j])\n",
    "                    \n",
    "                upsampled_act_img = cv2.resize(act_pattern, dsize=(original_img_size, original_img_size),\n",
    "                                             interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "                rescaled_act_img = upsampled_act_img - np.amin(upsampled_act_img)\n",
    "                rescaled_act_img = rescaled_act_img / np.amax(rescaled_act_img)\n",
    "                \n",
    "                heatmap = cv2.applyColorMap(np.uint8(255*rescaled_act_img), cv2.COLORMAP_JET)\n",
    "                heatmap = np.float32(heatmap) / 255\n",
    "                heatmap = heatmap[...,::-1]\n",
    "                overlayed_original_img = 0.5 * original_img + 0.3 * heatmap\n",
    "                \n",
    "                # construct the closest patch object\n",
    "                \n",
    "\n",
    "                # add to the j-th heap \n",
    "                if len(heaps[j]) < k:\n",
    "                    heapq.heappush(heaps[j], closest_patch)\n",
    "                else:\n",
    "                    # heappushpop runs more efficiently than heappush\n",
    "                    # followed by heappop\n",
    "                    heapq.heappushpop(heaps[j], closest_patch)\n",
    "                    \n",
    "    for j in range(n_prototypes):\n",
    "        heaps[j].sort()\n",
    "        heaps[j] = heaps[j][::-1]\n",
    "        dir_for_saving_images = os.path.join(root_dir_for_saving_images, str(j))\n",
    "        makedir(dir_for_saving_images)\n",
    "        for i, patch in enumerate(heaps[j]):\n",
    "            \n",
    "    \n",
    "    return\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81119f1-fd3c-4566-a23c-3acbf419c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find nearest patches\n",
      "1.0\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n"
     ]
    }
   ],
   "source": [
    "find_k_nearest_patches_to_prototypes(train_push_loader, # pytorch dataloader (must be unnormalized in [0,1])\n",
    "                                         ppnet_multi, # pytorch network with prototype_vectors\n",
    "                                         k=3,\n",
    "                                         preprocess_input_function=None, # normalize if needed\n",
    "                                         full_save=True, # save all the images\n",
    "                                         root_dir_for_saving_images='../saved_models/vgg19/004/nearest_images_100/',\n",
    "                                         log=print,\n",
    "                                         prototype_activation_function_in_numpy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbb454d-5792-437b-b48c-abe4a4be41de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
