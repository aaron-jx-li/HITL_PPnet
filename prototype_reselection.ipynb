{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96e18a60-9164-4d00-9413-8c8c405f6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch  \n",
    "import gym\n",
    "import numpy as np  \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.distributions.categorical import Categorical\n",
    "import math\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from preprocess import mean, std, preprocess_input_function\n",
    "from settings import train_dir, test_dir, train_push_dir, train_batch_size, test_batch_size, train_push_batch_size\n",
    "from settings import base_architecture, img_size, prototype_shape, num_classes, prototype_activation_function, add_on_layers_type\n",
    "from receptive_field import compute_rf_prototype\n",
    "import cv2\n",
    "from preference_model import construct_PrefNet, paired_cross_entropy_loss, PrefNet\n",
    "from tqdm import tqdm\n",
    "from settings import joint_optimizer_lrs, joint_lr_step_size\n",
    "import skimage as sk\n",
    "import skimage.io as skio\n",
    "import train_and_test as tnt\n",
    "from torch.utils.data import Subset\n",
    "import time\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f848e04f-aef8-4b9a-ab54-c077a6fd9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use PPnet's forward pass as the policy network (actor network); what about the network for value function (critic network)?\n",
    "Since there are only determinant actions, this is essentially A2C...\n",
    "'''\n",
    "class A3C_PPnet(nn.Module):\n",
    "    def __init__(self, PPnet, preference_model, k=3, p=5, learning_rate=1e-7, dummy_reward=False, train_batch_size=80):\n",
    "        super(A3C_PPnet, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.PPnet = PPnet.cuda()\n",
    "        #for param in self.PPnet.features.parameters():\n",
    "        #    param.requires_grad = True\n",
    "        self.k = k\n",
    "        self.pf_model = preference_model.cuda()\n",
    "        \n",
    "        #self.PPnet_multi = torch.nn.DataParallel(self.PPnet)\n",
    "        self.PPnet_multi = self.PPnet\n",
    "        for p in self.PPnet_multi.module.features.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.PPnet_multi.module.add_on_layers.parameters():\n",
    "            p.requires_grad = True\n",
    "        self.PPnet_multi.module.prototype_vectors.requires_grad = True\n",
    "        for p in self.PPnet_multi.module.last_layer.parameters():\n",
    "            p.requires_grad = False\n",
    "        #self.critic_model = self.construct_critic().cuda()\n",
    "        self.p = p\n",
    "        self.critic_model = Critic().cuda()\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.num_epoch = 0\n",
    "        policy_optimizer_specs = [#{'params': self.PPnet.features.parameters(), 'lr': joint_optimizer_lrs['features'], 'weight_decay': 1e-3}, \n",
    "                                  #{'params': self.PPnet.add_on_layers.parameters(), 'lr': joint_optimizer_lrs['add_on_layers'], 'weight_decay': 1e-3},\n",
    "                                  #{'params': self.PPnet.prototype_vectors, 'lr': joint_optimizer_lrs['prototype_vectors']},\n",
    "                                  #{'params': self.PPnet.add_on_layers.parameters(), 'lr': 1e-6, 'weight_decay': 0},\n",
    "                                  {'params': self.PPnet.module.prototype_vectors, 'lr': 1e-4, 'weight_decay': 1e-3}\n",
    "            \n",
    "                                  ]\n",
    "        self.policy_optimizer = torch.optim.Adam(policy_optimizer_specs)\n",
    "        #self.policy_optimizer = torch.optim.Adam(self.PPnet.features.parameters())\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic_model.parameters())\n",
    "        self.num_iteration = 0\n",
    "        \n",
    "    def get_heatmaps(self, batch_x, labels, dummy=False, track=False, save_prototypes=[], save_epochs=[]):\n",
    "        self.PPnet_multi.eval()\n",
    "        n_prototypes = self.PPnet_multi.module.num_prototypes\n",
    "        prototype_shape = self.PPnet_multi.module.prototype_shape\n",
    "        max_dist = prototype_shape[1] * prototype_shape[2] * prototype_shape[3]\n",
    "        protoL_rf_info = self.PPnet_multi.module.proto_layer_rf_info\n",
    "        \n",
    "        batch_x = batch_x.cuda()\n",
    "        protoL_input_torch, proto_dist_torch = self.PPnet_multi.module.push_forward(batch_x)\n",
    "        \n",
    "        proto_dist_ = proto_dist_torch.view(proto_dist_torch.shape[0], proto_dist_torch.shape[1], -1)\n",
    "        distances = torch.amin(proto_dist_, axis=-1)\n",
    "        #distances = torch.tensor(distances)\n",
    "        #print(\"Distances grad: \", distances.grad)\n",
    "        actions = self.sample_from_distances(distances, labels, track=track)\n",
    "        proto_dist = torch.clone(proto_dist_torch)\n",
    "        # Move to cpu and cast to numpy here\n",
    "        # proto_dist shape: (1000, 80, 7, 7)\n",
    "        proto_dist = torch.transpose(proto_dist, 0, 1)\n",
    "        proto_dist = proto_dist.detach().cpu().numpy()\n",
    "        heatmaps = []\n",
    "        joint_log_probs = []\n",
    "        r = []\n",
    "        patch_idx_batch = []\n",
    "        for action in actions:\n",
    "            img_idx, probs, j, class_identity = action[0], action[1], action[2], action[3]\n",
    "            heatmaps_j = []\n",
    "            r_j = []\n",
    "            #patch_idx_prototype\n",
    "            for i in img_idx:\n",
    "                # patch idx [0-6, 0-6]\n",
    "                closest_patch_indices_in_distance_map_j = list(np.unravel_index(np.argmin(proto_dist[j][i],axis=None), proto_dist[j][i].shape))\n",
    "                closest_patch_indices_in_distance_map_j = [0] + closest_patch_indices_in_distance_map_j\n",
    "                #print(closest_patch_indices_in_distance_map_j)\n",
    "                closest_patch_indices_in_img = compute_rf_prototype(batch_x.size(2), closest_patch_indices_in_distance_map_j, protoL_rf_info)\n",
    "                closest_patch = \\\n",
    "                    batch_x[i, :, closest_patch_indices_in_img[1]:closest_patch_indices_in_img[2], closest_patch_indices_in_img[3]:closest_patch_indices_in_img[4]]\n",
    "                closest_patch = closest_patch.cpu().numpy()\n",
    "                closest_patch = np.transpose(closest_patch, (1, 2, 0))\n",
    "\n",
    "                original_img = batch_x[i].cpu().numpy()\n",
    "                original_img = np.transpose(original_img, (1, 2, 0))\n",
    "                if self.PPnet_multi.module.prototype_activation_function == 'log':\n",
    "                    act_pattern = np.log((proto_dist[j][i] + 1)/(proto_dist[j][i] + self.PPnet_multi.module.epsilon))\n",
    "                elif self.PPnet_multi.module.prototype_activation_function == 'linear':\n",
    "                    act_pattern = max_dist - proto_dist[j][i]\n",
    "                else:\n",
    "                    act_pattern = prototype_activation_function_in_numpy(proto_dist[j][i])\n",
    "\n",
    "                patch_indices = closest_patch_indices_in_img[1:5]\n",
    "                #print(j)\n",
    "                #if j in [0, 1, 2, 3, 4]:\n",
    "                #print(patch_indices)\n",
    "                \n",
    "                img_size = original_img.shape[0]\n",
    "                \n",
    "                # dummy 1: centralize\n",
    "                #score = img_size * 2 - np.absolute(img_size//2 - patch_indices[0]) - np.absolute(img_size//2 - patch_indices[1]) - np.absolute(img_size//2 - patch_indices[2]) - np.absolute(img_size//2 - patch_indices[3])\n",
    "                #score = -(patch_indices[1] - patch_indices[0]) * (patch_indices[3] - patch_indices[2])\n",
    "            \n",
    "                # dummy 2: maximize area of heatmap\n",
    "                #score = (patch_indices[1]-patch_indices[0]) * (patch_indices[3] - patch_indices[2])\n",
    "                \n",
    "                #print(\"act_pattern: \", act_pattern.shape)\n",
    "                upsampled_act_pattern = cv2.resize(act_pattern, dsize=(img_size, img_size), interpolation=cv2.INTER_CUBIC)\n",
    "                rescaled_act_pattern = upsampled_act_pattern - np.amin(upsampled_act_pattern)\n",
    "                rescaled_act_pattern = rescaled_act_pattern / np.amax(rescaled_act_pattern)\n",
    "                \n",
    "                heatmap = cv2.applyColorMap(np.uint8(255*rescaled_act_pattern), cv2.COLORMAP_JET)\n",
    "                heatmap = np.float32(heatmap) / 255\n",
    "                heatmap = heatmap[..., ::-1]\n",
    "                overlayed_original_img = 0.5 * original_img + 1.0 * heatmap\n",
    "                overlayed_original_img = overlayed_original_img - np.amin(overlayed_original_img)\n",
    "                overlayed_original_img = overlayed_original_img / np.amax(overlayed_original_img)\n",
    "                \n",
    "                # dummy centralize:\n",
    "                center_filter = np.zeros((224, 224))\n",
    "                center_filter[90:134, 90:134] = 1\n",
    "                \n",
    "                center_filter[:30, :] = -0.01\n",
    "                center_filter[:, :30] = -0.01\n",
    "                center_filter[-30:, :] = -0.01\n",
    "                center_filter[:, -30:] = -0.01\n",
    "                \n",
    "                center_filter = cv2.GaussianBlur(center_filter, (15, 15), 100)\n",
    "                score = np.sum(rescaled_act_pattern * center_filter)\n",
    "                \n",
    "                #print(self.num_epoch, j)\n",
    "                #if self.num_epoch in save_epochs and j in save_prototypes:\n",
    "                    \n",
    "                    #plt.imsave(r'./A3C_results/004_epoch_'+str(self.num_epoch)+'_prototype_'+str(j)+'_best_'+str(len(heatmaps_j)+1)+'.jpg', overlayed_original_img)\n",
    "                if dummy:\n",
    "                    heatmaps_j.append(overlayed_original_img)\n",
    "                    r_j.append(score)\n",
    "                else:\n",
    "                    heatmaps_j.append(overlayed_original_img)\n",
    "            joint_log_prob = torch.prod(probs) * math.factorial(self.k)\n",
    "            #print(joint_log_prob.grad_fn)\n",
    "            heatmaps.append(heatmaps_j)\n",
    "            if dummy:\n",
    "                r.append(r_j)\n",
    "            joint_log_probs.append(joint_log_prob)\n",
    "                \n",
    "        # num_prototypes * self.k heatmaps in total\n",
    "        # num_prototypes probs\n",
    "        #for prob in joint_log_probs:\n",
    "        #    print(prob.grad_fn)\n",
    "        if dummy:\n",
    "            r = np.sum(np.array(r), axis=1)\n",
    "            r = torch.tensor(r)\n",
    "            return heatmaps, joint_log_probs, distances, r\n",
    "        return heatmaps, joint_log_probs, distances\n",
    "    \n",
    "    def sample_from_distances(self, distances, labels, track_iters=[], track=False):\n",
    "        '''\n",
    "        Takes in distances of shape (80, 1000)\n",
    "        returns actions of shape (1000, ), one for each prototype\n",
    "        '''\n",
    "        \n",
    "        distances = torch.clip(distances, min=1e-7, max=None)\n",
    "        similarities = 1 / distances\n",
    "        #print(similarities)\n",
    "        softmax_dist = F.log_softmax(similarities, dim=0)\n",
    "        softmax_dist = torch.transpose(softmax_dist, 0, 1)\n",
    "        # Maybe using combinatorics?\n",
    "        actions = []\n",
    "        # For each of the 1000 prototypes...\n",
    "        for i in range(softmax_dist.shape[0]):\n",
    "            class_identity = torch.argmax(self.PPnet_multi.module.prototype_class_identity[i])\n",
    "            #print(class_identity, class_identity.shape)\n",
    "            class_dist = softmax_dist[i][labels==class_identity]\n",
    "            \n",
    "            #print(class_dist, class_dist.shape)\n",
    "            if len(class_dist) > self.k:\n",
    "                #print(class_dist)\n",
    "                dist = Categorical(class_dist)\n",
    "                img_idx = dist.sample(sample_shape=torch.tensor([self.k]))\n",
    "                probs = dist.log_prob(img_idx)\n",
    "                probs = torch.exp(probs)\n",
    "                actions.append([img_idx, probs, i, class_identity])\n",
    "        return actions\n",
    "    \n",
    "    def construct_critic(self):\n",
    "        critic_model = nn.Sequential(\n",
    "                        nn.Linear(512 * self.k * 7 * 7, 120),\n",
    "                        nn.Sigmoid(),\n",
    "                        nn.Linear(120, 20),\n",
    "                        nn.Sigmoid(),\n",
    "                        nn.Linear(20, 1)\n",
    "                        )\n",
    "        return critic_model\n",
    "    \n",
    "    # Currently just the same architecture as the pref_net\n",
    "    '''\n",
    "    def critic(self, heatmaps):\n",
    "        values = torch.empty(len(heatmaps))\n",
    "        for i in tqdm(range(len(heatmaps))):\n",
    "            #x = torch.tensor(heatmaps[i])\n",
    "            x = np.concatenate(heatmaps[i], axis=1)\n",
    "            x = torch.tensor(x).cuda()\n",
    "            x = torch.unsqueeze(x, axis=0)\n",
    "            x = torch.transpose(x, 1, 3)\n",
    "            with torch.no_grad():\n",
    "                x = self.pf_model.conv_features(x)\n",
    "                x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "            x = self.critic_model(x)\n",
    "            values[i] = x\n",
    "            #print(i)\n",
    "        return values\n",
    "    '''\n",
    "    \n",
    "    # Need to vectorize\n",
    "    def get_critic_inputs(self, heatmaps, dummy=False):\n",
    "        critic_inputs = []\n",
    "        for i in range(len(heatmaps)):\n",
    "            x = np.concatenate(heatmaps[i], axis=1)\n",
    "            x = torch.tensor(x).cuda()\n",
    "            x = torch.unsqueeze(x, axis=0)\n",
    "            x = torch.transpose(x, 1, 3)\n",
    "            with torch.no_grad():\n",
    "                x = self.pf_model.conv_features(x)\n",
    "                x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "            critic_inputs.append(x)\n",
    "        #print(len(critic_inputs), critic_inputs[0].shape)\n",
    "        critic_inputs = torch.stack(critic_inputs, dim=0)\n",
    "        critic_inputs = critic_inputs.view(critic_inputs.shape[0], -1)\n",
    "        #print(critic_inputs.shape)\n",
    "        return critic_inputs\n",
    "        \n",
    "    def get_rewards(self, heatmaps, dummy=False):\n",
    "        if dummy:\n",
    "            h = heatmaps\n",
    "            rewards = np.empty(len(h))\n",
    "            for i in range(len(h)):\n",
    "                score = -np.sum(np.square(h[i][0]-h[i][1])) - np.sum(np.square(h[i][1]-h[i][2])) - np.sum(np.square(h[i][0]-h[i][2]))\n",
    "            rewards[i] = score\n",
    "            return torch.tensor(rewards)\n",
    "        with torch.no_grad():\n",
    "            rewards = torch.empty(len(heatmaps))\n",
    "            for i in range(len(heatmaps)):\n",
    "                pf_input = torch.tensor(np.array(heatmaps[i])).cuda()\n",
    "                pf_input = pf_input.view(pf_input.shape[0]*pf_input.shape[1], pf_input.shape[2], pf_input.shape[3])\n",
    "                pf_input = torch.transpose(pf_input, 0, 2)\n",
    "                pf_input = torch.transpose(pf_input, 1, 2)\n",
    "                pf_input = torch.unsqueeze(pf_input, axis=0)\n",
    "                reward = self.pf_model(pf_input)\n",
    "                rewards[i] = reward\n",
    "                #print(i)\n",
    "        return rewards\n",
    "        \n",
    "    def update_v1(self, rewards, values, probs):\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        for prob in probs:\n",
    "            prob = prob.cuda()\n",
    "        rewards = rewards.cuda()\n",
    "        values = values.cuda()\n",
    "        policy_loss = 0\n",
    "        '''\n",
    "        Customized A2C\n",
    "        '''\n",
    "        for i in range(len(rewards)):\n",
    "            policy_loss -= probs[i] * (rewards[i] - values[i])    \n",
    "        \n",
    "        '''\n",
    "        Reward Filtering\n",
    "        '''\n",
    "        #for i in range(len(rewards)):\n",
    "        #    if rewards[i] > 3000:\n",
    "        #        policy_loss -= probs[i] * rewards[i]\n",
    "        #if policy_loss != 0:\n",
    "        #    policy_loss.backward(retain_graph=True)\n",
    "        self.policy_optimizer.step()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        #print(list(self.critic_model.parameters())[0])\n",
    "        critic_loss = 0\n",
    "        for i in range(len(rewards)):\n",
    "            critic_loss += (rewards[i] - values[i]) ** 2\n",
    "        #print(critic_loss.grad_fn)\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "        #print(list(self.critic_model.parameters())[0])\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def update_v2(self, rewards, values, probs):\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def run(self, batch_x, labels, save_prototypes=[], save_epochs=[], track=False):\n",
    "\n",
    "        # action is n_prototypes * k heatmaps\n",
    "        heatmaps, probs, img_distances = self.get_heatmaps(batch_x, labels, track=track)\n",
    "        \n",
    "        '''\n",
    "        Not necessary for reward filtering\n",
    "        '''\n",
    "        critic_inputs = self.get_critic_inputs(heatmaps)\n",
    "        values = self.critic_model(critic_inputs)\n",
    "        \n",
    "        #print(\"Finished calculating values\")\n",
    "        rewards = self.get_rewards(heatmaps)\n",
    "        \n",
    "        self.update_v1(rewards, values, probs)\n",
    "        \n",
    "        #print(\"Finished updating. Done.\")\n",
    "        #if len(save_prototypes) > 0 and self.num_epoch in save_epochs:\n",
    "            #for p in save_prototypes:\n",
    "                #print(len(heatmaps))\n",
    "            #    for k in range(len(heatmaps[p])):\n",
    "            #        plt.imsave(r'./A3C_results/iter_'+str(self.num_iteration)+'_prototype_'+str(p)+'_best_'+str(k+1)+'.jpg', heatmaps[p][k])\n",
    "            \n",
    "        self.num_iteration += 1\n",
    "        if self.num_iteration == 75:\n",
    "            self.num_iteration = 0\n",
    "            self.num_epoch += 1\n",
    "        \n",
    "        return rewards, values, probs\n",
    "    \n",
    "    def run_v2():\n",
    "        return\n",
    "    \n",
    "    def run_dummy(self, batch_x, labels, save_prototypes=[], save_epochs=[], track=False):\n",
    "        heatmaps, probs, img_distances, rewards  = self.get_heatmaps(batch_x, labels, dummy=True, track=track, save_prototypes=save_prototypes, save_epochs=save_epochs)\n",
    "        \n",
    "        critic_inputs = self.get_critic_inputs(heatmaps)\n",
    "        values = self.critic_model(critic_inputs)\n",
    "        #values = []\n",
    "        self.update_v1(rewards, values, probs)\n",
    "        #if len(save_prototypes) > 0 and self.num_iteration in save_iters:\n",
    "        #    for p in save_prototypes:\n",
    "        #        \n",
    "        #        for k in range(len(heatmaps[p])):\n",
    "        #            plt.imsave(r'./A3C_results/epoch_'+str(self.num_epoch)+'_prototype_'+str(p)+'_best_'+str(k+1)+'_dummy.jpg', heatmaps[p][k])\n",
    "            \n",
    "        self.num_iteration += 1\n",
    "        if self.num_iteration == 75:\n",
    "            self.num_iteration = 0\n",
    "            self.num_epoch += 1\n",
    "        \n",
    "        return rewards, values, probs, heatmaps\n",
    "    \n",
    "    \n",
    "'''\n",
    "Not very useful so far\n",
    "'''\n",
    "def visualize_prototypes(ppnet_multi, data_loader, save_prototypes=[], exp_num=0, dummy=True):\n",
    "    ppnet_multi.eval()\n",
    "    n_prototypes = ppnet_multi.module.num_prototypes\n",
    "    prototype_shape = ppnet_multi.module.prototype_shape\n",
    "    max_dist = prototype_shape[1] * prototype_shape[2] * prototype_shape[3]\n",
    "    protoL_rf_info = ppnet_multi.module.proto_layer_rf_info\n",
    "\n",
    "    for i, (batch_x, labels) in tqdm(enumerate(dataloader)):\n",
    "        batch_x = batch_x.cuda()\n",
    "        protoL_input_torch, proto_dist_torch = ppnet_multi.module.push_forward(batch_x)\n",
    "\n",
    "        proto_dist_ = proto_dist_torch.view(proto_dist_torch.shape[0], proto_dist_torch.shape[1], -1)\n",
    "        distances = torch.amin(proto_dist_, axis=-1)\n",
    "        distances = torch.transpose(distances, 0, 1)\n",
    "        similarities = 1 / distances\n",
    "        # print(distances.shape)\n",
    "        \n",
    "        for j in p_idx:\n",
    "            top_idx = torch.topk(similarities[j], k).indices.cpu()\n",
    "            class_dist = similarities[j][labels==j]\n",
    "            \n",
    "            #print(class_dist, class_dist.shape)\n",
    "            if len(class_dist) > 3:\n",
    "                print(\"Prototype \"+str(j)+\": \", labels[top_idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26175d1f-388b-42b2-9261-c5151765424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, k=3, learning_rate=3e-4):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        '''\n",
    "        self.critic_linear1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.critic_linear2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        self.actor_linear1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.actor_linear2 = nn.Linear(hidden_size, num_actions)\n",
    "        '''\n",
    "        \n",
    "        self.k = k\n",
    "        self.fc1 = nn.Linear(512 * k * 7 * 7, 120)\n",
    "        self.fc2 = nn.Linear(120, 20)\n",
    "        self.fc3 = nn.Linear(20, 1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        out = torch.sigmoid(self.fc1(x))\n",
    "        out = torch.sigmoid(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f945cde-5fcb-458a-a69f-db261a3bd814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescaled pattern should be (224, 224)\n",
    "def get_dummy_reward(rescaled_pattern):\n",
    "    '''\n",
    "    center\n",
    "    '''\n",
    "    '''\n",
    "    center_filter = np.zeros((224, 224))\n",
    "    center_filter[90:134, 90:134] = 1\n",
    "\n",
    "    center_filter[:30, :] = -0.01\n",
    "    center_filter[:, :30] = -0.01\n",
    "    center_filter[-30:, :] = -0.01\n",
    "    center_filter[:, -30:] = -0.01\n",
    "\n",
    "    center_filter = cv2.GaussianBlur(center_filter, (15, 15), 100)\n",
    "    score = np.sum(rescaled_pattern * center_filter)\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    upper left corner\n",
    "    '''\n",
    "    '''\n",
    "    corner_filter = np.zeros((224, 224))\n",
    "    corner_filter[0:40, 0:40] = 1\n",
    "    corner_filter = cv2.GaussianBlur(corner_filter, (15, 15), 100)\n",
    "    score = np.sum(rescaled_pattern * corner_filter)\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    bottom right corner\n",
    "    '''\n",
    "    corner_filter = np.zeros((224, 224))\n",
    "    corner_filter[180:224, 180:224] = 1\n",
    "    corner_filter = cv2.GaussianBlur(corner_filter, (15, 15), 100)\n",
    "    score = np.sum(rescaled_pattern * corner_filter)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d7646a8-7311-46b8-aca0-7b02f8da3278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppnet = torch.load(r'../saved_models/vgg19/004/100_7push0.7344.pth')\n",
    "ppnet = torch.nn.DataParallel(ppnet)\n",
    "pf_model = construct_PrefNet(\"resnet18\")\n",
    "pf_model.load_state_dict(torch.load(\"./human_comparisons/pref_model_009_65+35_ep50_adam_0.0001\"))\n",
    "#pf_model = torch.load(r'./human_comparisons/pref_model_009_65+35_ep50_adam_0.0001_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a8c91bc-05b6-40f5-9f47-f93b672ed33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "        train_push_dir,\n",
    "        transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=80, shuffle=False,\n",
    "    num_workers=2, pin_memory=False)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "        test_dir,\n",
    "        transforms.Compose([\n",
    "            transforms.Resize(size=(img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=test_batch_size, shuffle=False,\n",
    "    num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "#shuffled_dataset = Subset(train_dataset, shuffled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68a03359-6270-4685-b58c-ca1bcdad8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "\n",
    "'''\n",
    "Each batch of size 80 consists of 16 shuffled blocks\n",
    "'''\n",
    "for i in range(200):\n",
    "    class_i = [ind for ind, ele in enumerate(train_dataset.targets) if ele == i]\n",
    "    indices.append(class_i[:5])\n",
    "    indices.append(class_i[5:10])\n",
    "    indices.append(class_i[10:15])\n",
    "    indices.append(class_i[15:20])\n",
    "    indices.append(class_i[20:25])\n",
    "    indices.append(class_i[25:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed76cb56-8fa7-4477-ba4d-d4ef39fb9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "a3c = A3C_PPnet(ppnet, pf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c3b1e51-d4af-4412-92cd-7b4a89c7a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reselect_prototypes(a3c, reward_threshold, data_loader, heatmaps):\n",
    "    # get the heatmaps by searching for the closest images in the entire dataset\n",
    "    # can use different k values\n",
    "    # heatmaps: (1000, 1, 224, 224, 3)\n",
    "    # rewards: (1000,)\n",
    "    prototype_shape = a3c.PPnet_multi.module.prototype_shape\n",
    "    bad_prototype_idx = []\n",
    "    rewards = []\n",
    "    for i in range(len(heatmaps)):\n",
    "        reward = get_dummy_reward(heatmaps[i][0])\n",
    "        rewards.append(reward)\n",
    "        if reward < reward_threshold:\n",
    "            bad_prototype_idx.append(i)\n",
    "    \n",
    "    global_max_rewards = np.zeros((200, 5))\n",
    "    global_best_patches = torch.zeros((200, 5, 128, 1, 1)).cuda()\n",
    "    \n",
    "    class_comps = np.zeros((200, 5))\n",
    "    \n",
    "    for idx, (batch_x, labels) in tqdm(enumerate(data_loader)):\n",
    "        a3c.PPnet_multi.eval()\n",
    "        n_prototypes = a3c.PPnet_multi.module.num_prototypes\n",
    "        prototype_shape = a3c.PPnet_multi.module.prototype_shape\n",
    "        max_dist = prototype_shape[1] * prototype_shape[2] * prototype_shape[3]\n",
    "        protoL_rf_info = a3c.PPnet_multi.module.proto_layer_rf_info\n",
    "        \n",
    "        batch_x = batch_x.cuda()\n",
    "        # conv_outs: (80, 128, 7, 7)\n",
    "        conv_outs = a3c.PPnet_multi.module.conv_features(batch_x)\n",
    "\n",
    "        # loop over each prototype\n",
    "        for j in bad_prototype_idx:\n",
    "            class_identity = torch.argmax(a3c.PPnet_multi.module.prototype_class_identity[j])\n",
    "            class_outs = conv_outs[labels == class_identity]\n",
    "            if class_outs.shape[0] == 0:\n",
    "                continue\n",
    "            height = class_outs.shape[2]\n",
    "            width = class_outs.shape[3]\n",
    "            \n",
    "            for img_idx in range(class_outs.shape[0]):\n",
    "                img_max_reward = 0\n",
    "                img_best_patch = a3c.PPnet_multi.module.prototype_vectors.data[j]\n",
    "                for h in range(height):\n",
    "                    for w in range(width):\n",
    "                        # actually old_vec might not be necessary\n",
    "                        # old_vec = np.copy(a3c.PPnet_multi.module.prototype_vectors.data[j])\n",
    "                        patch_candidate = class_outs[img_idx, :, h:h+1, w:w+1]\n",
    "                        a3c.PPnet_multi.module.prototype_vectors.data[j] = patch_candidate\n",
    "                        #a3c.PPnet_multi.module.prototype_vectors.data.copy_(vec)\n",
    "                        # distances: (7, 7)\n",
    "                        distances = a3c.PPnet_multi.module._l2_convolution(class_outs[img_idx])[j].detach().cpu().numpy()\n",
    "                        \n",
    "                        if a3c.PPnet_multi.module.prototype_activation_function == 'log':\n",
    "                            act_pattern = np.log((distances + 1)/(distances + a3c.PPnet_multi.module.epsilon))\n",
    "                        elif a3c.PPnet_multi.module.prototype_activation_function == 'linear':\n",
    "                            act_pattern = max_dist - distances\n",
    "                        else:\n",
    "                            act_pattern = prototype_activation_function_in_numpy(distances)\n",
    "                            \n",
    "                        upsampled_act_pattern = cv2.resize(act_pattern, dsize=(img_size, img_size), interpolation=cv2.INTER_CUBIC)\n",
    "                        rescaled_act_pattern = upsampled_act_pattern - np.amin(upsampled_act_pattern)\n",
    "                        rescaled_act_pattern = rescaled_act_pattern / np.amax(rescaled_act_pattern)\n",
    "                        \n",
    "                        patch_reward = get_dummy_reward(rescaled_act_pattern)\n",
    "                        \n",
    "                        if patch_reward > img_max_reward:\n",
    "                            img_max_reward = patch_reward\n",
    "                            img_best_patch = patch_candidate\n",
    "                        #else:\n",
    "                        #    a3c.PPnet_multi.module.prototype_vectors.data[j] = old_vec\n",
    "                            \n",
    "                \n",
    "                min_index = int(class_comps[class_identity][-1])\n",
    "                if img_max_reward > global_max_rewards[class_identity][min_index]:\n",
    "                    global_max_rewards[class_identity][min_index] = img_max_reward\n",
    "                    global_best_patches[class_identity][min_index] = img_best_patch\n",
    "                    class_comps[class_identity] = np.flip(np.argsort(global_max_rewards[class_identity]))\n",
    "                   \n",
    "    #print(class_comps)\n",
    "    #print(global_max_rewards)\n",
    "    for i in bad_prototype_idx:\n",
    "        class_num = int(i // 5)\n",
    "        p_num = int(class_comps[class_num][0])\n",
    "        class_comps[class_num] = np.roll(class_comps[class_num], -1)\n",
    "        a3c.PPnet_multi.module.prototype_vectors.data[i] = global_best_patches[class_num][p_num]\n",
    "        \n",
    "    return global_max_rewards\n",
    "                        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e905c0d8-506d-474c-a4a7-1bb6e1f129ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find nearest patches\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "\tfind nearest patches time: \t374.49913930892944\n"
     ]
    }
   ],
   "source": [
    "heatmaps = find_k_nearest_patches_to_prototypes(train_loader, a3c.PPnet_multi, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcb4a954-661b-43f7-b644-8b04922905f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [35:53, 28.71s/it]\n"
     ]
    }
   ],
   "source": [
    "global_max_rewards = reselect_prototypes(a3c, 300, train_loader, heatmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5fd98f-4526-437e-9147-698152a64522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24a886e0-c086-4344-bd08-16f2f4c7e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(a3c.PPnet_multi, r'./A3C_results/reselection_dummy_a3c_corner_bottom_right.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13768913-e513-421f-911a-e1f330ca9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f8012bf-1472-4c7c-9cb6-0817baeea82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_prototypes(a3c):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7b4aa26-f3ef-4c90-8b77-e6640bc76884",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePatch:\n",
    "\n",
    "    def __init__(self, patch, label, distance,\n",
    "                 original_img=None, act_pattern=None, patch_indices=None):\n",
    "        self.patch = patch\n",
    "        self.label = label\n",
    "        self.negative_distance = -distance\n",
    "\n",
    "        self.original_img = original_img\n",
    "        self.act_pattern = act_pattern\n",
    "        self.patch_indices = patch_indices\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.negative_distance < other.negative_distance\n",
    "\n",
    "\n",
    "class ImagePatchInfo:\n",
    "\n",
    "    def __init__(self, label, distance):\n",
    "        self.label = label\n",
    "        self.negative_distance = -distance\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.negative_distance < other.negative_distance\n",
    "\n",
    "def find_k_nearest_patches_to_prototypes(dataloader, # pytorch dataloader (must be unnormalized in [0,1])\n",
    "                                         prototype_network_parallel, # pytorch network with prototype_vectors\n",
    "                                         k=3,\n",
    "                                         preprocess_input_function=None, # normalize if needed\n",
    "                                         full_save=False, # save all the images\n",
    "                                         root_dir_for_saving_images='./nearest',\n",
    "                                         log=print,\n",
    "                                         prototype_activation_function_in_numpy=None, heatmap_ratio = 1.0):\n",
    "    prototype_network_parallel.eval()\n",
    "    '''\n",
    "    full_save=False will only return the class identity of the closest\n",
    "    patches, but it will not save anything.\n",
    "    '''\n",
    "    log('find nearest patches')\n",
    "    start = time.time()\n",
    "    n_prototypes = prototype_network_parallel.module.num_prototypes\n",
    "    \n",
    "    prototype_shape = prototype_network_parallel.module.prototype_shape\n",
    "    max_dist = prototype_shape[1] * prototype_shape[2] * prototype_shape[3]\n",
    "\n",
    "    protoL_rf_info = prototype_network_parallel.module.proto_layer_rf_info\n",
    "\n",
    "    heaps = []\n",
    "    # allocate an array of n_prototypes number of heaps\n",
    "    for _ in range(n_prototypes):\n",
    "        # a heap in python is just a maintained list\n",
    "        heaps.append([])\n",
    "\n",
    "    for idx, (search_batch_input, search_y) in tqdm(enumerate(dataloader)):\n",
    "        #print('batch {}'.format(idx))\n",
    "        if preprocess_input_function is not None:\n",
    "            # print('preprocessing input for pushing ...')\n",
    "            # search_batch = copy.deepcopy(search_batch_input)\n",
    "            search_batch = preprocess_input_function(search_batch_input)\n",
    "\n",
    "        else:\n",
    "            search_batch = search_batch_input\n",
    "\n",
    "        with torch.no_grad():\n",
    "            search_batch = search_batch.cuda()\n",
    "            protoL_input_torch, proto_dist_torch = \\\n",
    "                prototype_network_parallel.module.push_forward(search_batch)\n",
    "\n",
    "        #protoL_input_ = np.copy(protoL_input_torch.detach().cpu().numpy())\n",
    "        proto_dist_ = np.copy(proto_dist_torch.detach().cpu().numpy())\n",
    "        \n",
    "        # proto_dist_: (80, 1000, 7, 7)\n",
    "\n",
    "        for img_idx, distance_map in enumerate(proto_dist_):\n",
    "            for j in range(n_prototypes):\n",
    "                # find the closest patches in this batch to prototype j\n",
    "\n",
    "                closest_patch_distance_to_prototype_j = np.amin(distance_map[j])\n",
    "\n",
    "\n",
    "\n",
    "                closest_patch_indices_in_distance_map_j = \\\n",
    "                    list(np.unravel_index(np.argmin(distance_map[j],axis=None),\n",
    "                                          distance_map[j].shape))\n",
    "                closest_patch_indices_in_distance_map_j = [0] + closest_patch_indices_in_distance_map_j\n",
    "                closest_patch_indices_in_img = \\\n",
    "                    compute_rf_prototype(search_batch.size(2),\n",
    "                                         closest_patch_indices_in_distance_map_j,\n",
    "                                         protoL_rf_info)\n",
    "                closest_patch = \\\n",
    "                    search_batch_input[img_idx, :,\n",
    "                                       closest_patch_indices_in_img[1]:closest_patch_indices_in_img[2],\n",
    "                                       closest_patch_indices_in_img[3]:closest_patch_indices_in_img[4]]\n",
    "                closest_patch = closest_patch.numpy()\n",
    "                closest_patch = np.transpose(closest_patch, (1, 2, 0))\n",
    "\n",
    "                original_img = search_batch_input[img_idx].numpy()\n",
    "                original_img = np.transpose(original_img, (1, 2, 0))\n",
    "\n",
    "                if prototype_network_parallel.module.prototype_activation_function == 'log':\n",
    "                    act_pattern = np.log((distance_map[j] + 1)/(distance_map[j] + prototype_network_parallel.module.epsilon))\n",
    "                elif prototype_network_parallel.module.prototype_activation_function == 'linear':\n",
    "                    act_pattern = max_dist - distance_map[j]\n",
    "                else:\n",
    "                    act_pattern = prototype_activation_function_in_numpy(distance_map[j])\n",
    "\n",
    "                # 4 numbers: height_start, height_end, width_start, width_end\n",
    "                patch_indices = closest_patch_indices_in_img[1:5]\n",
    "\n",
    "                # construct the closest patch object\n",
    "                closest_patch = ImagePatch(patch=closest_patch,\n",
    "                                           label=search_y[img_idx],\n",
    "                                           distance=closest_patch_distance_to_prototype_j,\n",
    "                                           original_img=original_img,\n",
    "                                           act_pattern=act_pattern,\n",
    "                                           patch_indices=patch_indices)\n",
    "                '''\n",
    "                else:\n",
    "                \n",
    "                closest_patch = ImagePatchInfo(label=search_y[img_idx],\n",
    "                                                   distance=closest_patch_distance_to_prototype_j)\n",
    "                '''\n",
    "\n",
    "                # add to the j-th heap \n",
    "                if len(heaps[j]) < k:\n",
    "                    heapq.heappush(heaps[j], closest_patch)\n",
    "                else:\n",
    "                    # heappushpop runs more efficiently than heappush\n",
    "                    # followed by heappop\n",
    "                    heapq.heappushpop(heaps[j], closest_patch)\n",
    "                    \n",
    "\n",
    "    # after looping through the dataset every heap will\n",
    "    # have the k closest prototypes\n",
    "    heatmaps = []\n",
    "    for j in range(n_prototypes):\n",
    "        # finally sort the heap; the heap only contains the k closest\n",
    "        # but they are not ranked yet\n",
    "        heaps[j].sort()\n",
    "        heaps[j] = heaps[j][::-1]\n",
    "\n",
    "        \n",
    "        heatmaps_j = []\n",
    "        for i, patch in enumerate(heaps[j]):\n",
    "            \n",
    "            img_size = patch.original_img.shape[0]\n",
    "            upsampled_act_pattern = cv2.resize(patch.act_pattern,\n",
    "                                               dsize=(img_size, img_size),\n",
    "                                               interpolation=cv2.INTER_CUBIC)\n",
    "            rescaled_act_pattern = upsampled_act_pattern - np.amin(upsampled_act_pattern)\n",
    "            rescaled_act_pattern = rescaled_act_pattern / np.amax(rescaled_act_pattern)\n",
    "            \n",
    "            # No need for these if using dummy reward model\n",
    "            '''\n",
    "            heatmap = cv2.applyColorMap(np.uint8(255*rescaled_act_pattern), cv2.COLORMAP_JET)\n",
    "            heatmap = np.float32(heatmap) / 255\n",
    "            heatmap = heatmap[...,::-1]\n",
    "\n",
    "            overlayed_original_img = 0.5 * patch.original_img + heatmap_ratio * heatmap\n",
    "            overlayed_original_img = overlayed_original_img - np.amin(overlayed_original_img)\n",
    "            overlayed_original_img = overlayed_original_img / np.amax(overlayed_original_img)\n",
    "            '''\n",
    "            heatmaps_j.append(rescaled_act_pattern)\n",
    "        heatmaps.append(heatmaps_j)\n",
    "    end = time.time()\n",
    "    log('\\tfind nearest patches time: \\t{0}'.format(end - start))\n",
    "\n",
    "    return heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c91134d-612a-4304-b4f5-57edbad2af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_reward(rescaled_pattern):\n",
    "    '''\n",
    "    center\n",
    "    '''\n",
    "    '''\n",
    "    center_filter = np.zeros((224, 224))\n",
    "    center_filter[90:134, 90:134] = 1\n",
    "\n",
    "    center_filter[:30, :] = -0.01\n",
    "    center_filter[:, :30] = -0.01\n",
    "    center_filter[-30:, :] = -0.01\n",
    "    center_filter[:, -30:] = -0.01\n",
    "\n",
    "    center_filter = cv2.GaussianBlur(center_filter, (15, 15), 100)\n",
    "    score = np.sum(rescaled_pattern * center_filter)\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    upper left corner\n",
    "    '''\n",
    "    '''\n",
    "    corner_filter = np.zeros((224, 224))\n",
    "    corner_filter[0:40, 0:40] = 1\n",
    "    corner_filter = cv2.GaussianBlur(corner_filter, (15, 15), 100)\n",
    "    score = np.sum(rescaled_pattern * corner_filter)\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    bottom right corner\n",
    "    '''\n",
    "    corner_filter = np.zeros((224, 224))\n",
    "    corner_filter[180:224, 180:224] = 1\n",
    "    corner_filter = cv2.GaussianBlur(corner_filter, (15, 15), 100)\n",
    "    score = np.sum(rescaled_pattern * corner_filter)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3127213-d5a4-4217-ace4-f1365cd9abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_reward_004 = []\n",
    "reselection_epochs = [19, 59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3762704-0d34-4979-9d12-488e44adbd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "a3c = A3C_PPnet(ppnet, pf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb0898-4056-4dfe-9150-9da1415a6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Actual human feedback data & prototype reselection\n",
    "'''\n",
    "for epoch in range(100):\n",
    "    order = np.random.permutation(1200)\n",
    "    shuffled_idx = []\n",
    "    for idx in order:\n",
    "        shuffled_idx += indices[idx]\n",
    "    #print(shuffled_idx)\n",
    "    shuffled_dataset = Subset(train_dataset, shuffled_idx)\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "    shuffled_dataset, batch_size=80, shuffle=False,\n",
    "    num_workers=2, pin_memory=False)\n",
    "    \n",
    "    epoch_reward = 0\n",
    "    \n",
    "    for i, (batch, labels) in tqdm(enumerate(dataloader)):\n",
    "        rewards, values, probs, heatmaps = a3c.run(batch, labels, save_prototypes=[], save_epochs=[])\n",
    "        \n",
    "        total_reward = 0\n",
    "        mse_loss = 0\n",
    "        for j in range(len(probs)):\n",
    "            \n",
    "            probs[j].detach().cpu().numpy()\n",
    "            rewards[j].detach().cpu().numpy()\n",
    "            total_reward += probs[j] * rewards[j]\n",
    "            #mse_loss += (rewards[j] - values[j]) ** 2\n",
    "            \n",
    "            #probs[j].detach().cpu().numpy()\n",
    "            #rewards[j].detach().cpu().numpy()\n",
    "        epoch_reward += total_reward.item()\n",
    "    \n",
    "    if epoch in reselection_epochs:\n",
    "        heatmaps = find_k_nearest_patches_to_prototypes(train_loader, a3c.PPnet_multi, k=3)\n",
    "        \n",
    "        \n",
    "    \n",
    "    print(\"Epoch \"+str(a3c.num_epoch)+\" \"+str(i)+\" average reward: \", epoch_reward/i)\n",
    "    avg_reward_004.append(epoch_reward/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a40f34-d2c4-4f91-b83e-f52050302555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
